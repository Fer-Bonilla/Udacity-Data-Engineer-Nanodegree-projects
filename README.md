# Udacity Data Engineering Nanodegree program

Repository for Undacity's Engineering Nanodegree program. Learn to design data models, build data warehouses and data lakes, automate data pipelines, and work with massive datasets. At the end of the program, you’ll combine your new skills by completing a capstone project.

# Course program

## 1. Data Modeling

   Learn to create relational and NoSQL data models to fit the diverse needs of data consumers. Use ETL to build databases in PostgreSQL and Apache Cassandra.
   
   **Project 1: Data Modeling with Postgres**

   In this project, you’ll model user activity data for a music streaming app called Sparkify. You’ll create a relational database and ETL pipeline designed to optimize queries for understanding what songs users are listening to. In PostgreSQL you will also define Fact and Dimension tables and insert data into your new tables.

   *project 1 link:* [Data Modeling with Postgres](https://github.com/Fer-Bonilla/Udacity-Data-Engineering-data-modeling-with-postgres)

   **Project 2: Data Modeling with Apache Cassandra**

   In this project, you’ll model user activity data for a music streaming app called Sparkify. You’ll create a noSQL database and ETL pipeline designed to optimize queries for understanding what songs users are listening to. You’ll model your data in Apache Cassandra to allow for specific queries provided by the analytics team at Sparkify.

   *project 2 link:* [Data Modeling with Apache Cassandra](https://github.com/Fer-Bonilla/Udacity-Data-Engineering-data-modeling-with-cassandra)


## 2. Cloud Data Warehouses

   Sharpen your data warehousing skills and deepen your understanding of data infrastructure. Create cloud-based data warehouses on Amazon Web Services (AWS).
   
   **Project: Build a Cloud Data Warehouse**

   In this project, you are tasked with building an ETL pipeline that extracts their data from S3, stages them in Redshift, and transforms data into a set of dimensional tables for their analytics team to continue finding insights in what songs their users are listening to.

   *project link:* [Build a Cloud Data Warehouse](https://github.com/Fer-Bonilla/Udacity-Data-Engineering-datawarehouse-with-aws-redshift)


## 3. Spark and Data Lakes

   Understand the big data ecosystem and how to use Spark to work with massive datasets. Store big data in a data lake and query it with Spark.
    
   **Project: Build a Cloud Data Warehouse**
   
   In this project, you'll build an ETL pipeline for a data lake. The data resides in S3, in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in the app. You will load data from S3, process the data into analytics tables using Spark, and load them back into S3. You'll deploy this Spark process on a cluster using AWS.
      
   *project link:* [Build a Data Lake](https://github.com/Fer-Bonilla/Udacity-Data-Engineering-datalake-with-aws-spark)


## 4. Data Pipelines with Airflow

   Schedule, automate, and monitor data pipelines using Apache Airflow. Run data quality checks, track data lineage, and work with data pipelines in production
   
   **Data Pipelines with Airflow*}
     
   *project link:* [Data Pipelines with Airflow](https://github.com/Fer-Bonilla/Udacity-Data-Engineering-data-pipelines-with-airflow)
   
   
## 5. Capstone Project

   Combine what you've learned throughout the program to build your own data engineering portfolio project
   
   **Project: Build a Cloud Data Warehouse**
    
   The purpose of the data engineering capstone project is to give you a chance to combine what you've learned throughout the program. You'll define the scope of the project and the data you'll be working with. You'll gather data from several different data sources; transform, combine, and summarize it; and create a clean database for others to analyze.  
     
   *project link:* [Data Pipeline to process Bitcoin and Ethereum daily prices](https://github.com/Fer-Bonilla/Udacity-Data-Engineering-capstone-project)   
